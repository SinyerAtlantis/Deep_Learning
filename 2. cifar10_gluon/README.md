
cifar10分类精度对比：(草稿中)

| 模型               | 训练轮数 | 精度(%) | 平均每轮时间(s) |
| ---------------- | ---- | ----- | --------- |
| mlp              | 140  | 53.78 | 1.0       |
| lenet            | 80   | 69.62 | 1.8       |
| lenet_aug        | 120  | 81.40 | 10.8      |
| resnet50         | 60   | 88.07 | 30.1      |
| resnet50_aug     | 160  | 94.20 | 47.8      |
| wide_resnet16\*8 | 160  |       |           |

batch_size：128

GPU：GTX 1070

其余具体参数见代码


一些调参时的体会：

- 数据增强会减小训练准确率和测试准确率之间的差值，收敛也会变慢，不过一般会获得更好的效果。
- 从cifar-10的结果看，模型的改进能获得确实的效果。
- 更强的权重衰减有可能提升模型的精度。
- 过早或者过晚decay学习率都可能造成精度的下降。

